"""
Automated Outbound Sales Email Campaign - LangGraph Implementation
Converts n8n workflow to LangGraph for automated lead generation and outreach
"""

import os
import time
import logging
from typing import TypedDict, List, Dict, Any, Optional
from urllib.parse import urlparse

# External dependencies
import requests
from bs4 import BeautifulSoup
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
import pickle
from openai import OpenAI

# LangGraph imports
from langgraph.graph import StateGraph, END

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURATION
# ============================================================================

# API Keys and Credentials (set via environment variables)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
HUNTER_API_KEY = os.getenv("HUNTER_API_KEY")
GOOGLE_SHEETS_SPREADSHEET_ID = os.getenv("GOOGLE_SHEET_ID", "1Z9wgLcyYLXFMXiLm-MOme0bmjJdS1X7prWVTIC7czaM")
TOKEN_FILE = os.getenv("TOKEN_FILE", "adc_token.json")



# Google OAuth Scopes
GOOGLE_SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/gmail.compose'
]

# OpenAI Configuration
OPENAI_MODEL = "gpt-4o-mini"  # Can be changed to gpt-4o-mini for cost savings
OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# Rate limiting delays (in seconds)
DELAY_BETWEEN_REQUESTS = 1
HUNTER_API_DELAY = 2

# ============================================================================
# STATE DEFINITION
# ============================================================================

class WorkflowState(TypedDict):
    """State schema for the outbound sales workflow"""
    # Current processing state
    company_urls: List[str]  # List of all company URLs to process
    current_index: int  # Current position in the company_urls list
    current_company_url: Optional[str]  # Currently processing URL
    
    # Extracted/Generated data
    html_content: Optional[str]
    text_content: Optional[str]
    company_summary: Optional[str]
    company_domain: Optional[str]
    
    # Hunter.io results
    hunter_results: Optional[Dict[str, Any]]
    contact_emails: List[Dict[str, str]]
    organization_name: Optional[str]
    
    # Email generation
    email_body: Optional[str]
    email_subject: Optional[str]
    target_email: Optional[str]
    
    # Status tracking
    emails_found: bool
    processing_complete: bool
    success_logged: bool
    failure_logged: bool
    
    # Error tracking
    errors: List[str]
    
    # Gmail draft
    draft_id: Optional[str]

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def get_google_credentials():
    """Get Google credentials from the ADC token file generated by gcp.py."""
    creds = None

    try:
        from google_auth_oauthlib.flow import InstalledAppFlow
        from google.oauth2.credentials import Credentials

        import json

        if not os.path.exists("token.json"):
            SCOPES = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/gmail.modify",
            ]

            flow = InstalledAppFlow.from_client_secrets_file(
            "credentials.json", SCOPES, redirect_uri="http://localhost:8080/"
            )

            # Generate the authorization URL
            auth_url, _ = flow.authorization_url(prompt="consent")

            print("Please go to this URL and authorize the application:")
            print(auth_url)
            print("-" * 30)

            # Wait for the user to paste the authorization code
            code = input("Enter the authorization code from the browser: ")

            # Exchange the code for a token
            flow.fetch_token(code=code)
            creds = flow.credentials
            token_json_string = creds.to_json()
            with open("token.json", "w") as token_file:
                token_file.write(token_json_string)

            print("\nSUCCESS! Token saved to token.json")
        else:
            with open("token.json", "r") as token_file:
                token_json_string = token_file.read()
                creds = Credentials.from_authorized_user_info(json.loads(token_json_string))


        return creds

    except ImportError as e:
        logger.error(f"Missing required libraries for Google authentication: {e}")
        return None
    except Exception as e:
        logger.error(f"Failed to load or refresh credentials: {e}")
        return None

def extract_domain_from_url(url: str) -> str:
    """Extract domain from URL (removes protocol and path)"""
    try:
        parsed = urlparse(url)
        domain = parsed.netloc or parsed.path
        # Remove www. prefix if present
        if domain.startswith('www.'):
            domain = domain[4:]
        return domain
    except Exception as e:
        logger.error(f"Error extracting domain from {url}: {e}")
        return ""

def clean_text_content(text: str, max_length: int = 5000) -> str:
    """Clean and truncate text content for processing"""
    if not text:
        return ""
    
    # Remove extra whitespace
    text = ' '.join(text.split())
    
    # Truncate if too long
    if len(text) > max_length:
        text = text[:max_length] + "..."
    
    return text

# ============================================================================
# NODE IMPLEMENTATIONS
# ============================================================================

def initialize_workflow(state: WorkflowState) -> WorkflowState:
    """Initialize the workflow state - replaces manual trigger"""
    logger.info("Starting automated outbound sales workflow")
    
    return {
        **state,
        "current_index": 0,
        "processing_complete": False,
        "errors": []
    }

def read_google_sheets(state: WorkflowState) -> WorkflowState:
    """Read company URLs from Google Sheets - Node: Google Sheets"""
    logger.info("Reading company URLs from Google Sheets")
    
    try:
        creds = get_google_credentials()
        service = build('sheets', 'v4', credentials=creds)
        
        # Read from Sheet1, column A
        range_name = 'Sheet1!A1:A'
        result = service.spreadsheets().values().get(
            spreadsheetId=GOOGLE_SHEETS_SPREADSHEET_ID,
            range=range_name
        ).execute()
        
        values = result.get('values', [])
        
        if not values:
            logger.warning("No URLs found in Google Sheets")
            return {**state, "company_urls": [], "processing_complete": True}
        
        # Extract URLs (skip header if present)
        urls = []
        for row in values:
            if row and row[0]:
                url = row[0].strip()
                # Skip if it looks like a header
                if not url.lower().startswith('company') and url.startswith('http'):
                    urls.append(url)
        
        logger.info(f"Found {len(urls)} company URLs to process")
        return {**state, "company_urls": urls}
        
    except Exception as e:
        logger.error(f"Error reading Google Sheets: {e}")
        return {
            **state, 
            "errors": state.get("errors", []) + [f"Google Sheets read error: {str(e)}"],
            "processing_complete": True
        }

def select_next_company(state: WorkflowState) -> WorkflowState:
    """Select the next company URL to process"""
    current_index = state.get("current_index", 0)
    company_urls = state.get("company_urls", [])
    
    if current_index < len(company_urls):
        current_url = company_urls[current_index]
        logger.info(f"Processing company {current_index + 1}/{len(company_urls)}: {current_url}")
        
        return {
            **state,
            "current_company_url": current_url,
            "current_index": current_index,
            # Reset per-company state
            "html_content": None,
            "text_content": None,
            "company_summary": None,
            "hunter_results": None,
            "contact_emails": [],
            "email_body": None,
            "email_subject": None,
            "emails_found": False,
            "success_logged": False,
            "failure_logged": False,
            "draft_id": None
        }
    else:
        logger.info("All companies processed")
        return {**state, "processing_complete": True}

def fetch_website(state: WorkflowState) -> WorkflowState:
    """Fetch website HTML content - Node: HTTP Request"""
    url = state.get("current_company_url")
    if not url:
        return state
    
    logger.info(f"Fetching website content from {url}")
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=30, allow_redirects=True)
        response.raise_for_status()
        
        time.sleep(DELAY_BETWEEN_REQUESTS)
        
        return {**state, "html_content": response.text}
        
    except Exception as e:
        logger.error(f"Error fetching website {url}: {e}")
        return {
            **state,
            "errors": state.get("errors", []) + [f"HTTP fetch error for {url}: {str(e)}"]
        }

def extract_text_content(state: WorkflowState) -> WorkflowState:
    """Extract text from HTML body - Node: HTML"""
    html = state.get("html_content")
    if not html:
        return state
    
    logger.info("Extracting text content from HTML")
    
    try:
        soup = BeautifulSoup(html, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Extract body text
        body = soup.find('body')
        if body:
            text = body.get_text(separator=' ', strip=True)
            text = clean_text_content(text)
            return {**state, "text_content": text}
        else:
            return {**state, "text_content": soup.get_text(separator=' ', strip=True)}
            
    except Exception as e:
        logger.error(f"Error extracting text: {e}")
        return {
            **state,
            "errors": state.get("errors", []) + [f"HTML extraction error: {str(e)}"]
        }

def summarize_company(state: WorkflowState) -> WorkflowState:
    """Generate company summary using OpenAI - Node: OpenAI-Summarizer"""
    text_content = state.get("text_content")
    if not text_content or not OPENAI_CLIENT:
        return state
    
    logger.info("Generating company summary with OpenAI")
    
    try:
        prompt = f"""Summarize the following website content. Focus on what the company does and its main value proposition. Keep it concise, under 75 words. Here is the content: {text_content[:3000]}"""
        
        response = OPENAI_CLIENT.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=150,
            temperature=0.7
        )
        
        summary = response.choices[0].message.content
        logger.info(f"Summary generated: {summary[:100]}...")
        
        # Extract domain for Hunter.io
        domain = extract_domain_from_url(state.get("current_company_url", ""))
        
        return {**state, "company_summary": summary, "company_domain": domain}
        
    except Exception as e:
        logger.error(f"Error generating summary: {e}")
        return {
            **state,
            "errors": state.get("errors", []) + [f"OpenAI summary error: {str(e)}"]
        }

def find_contacts(state: WorkflowState) -> WorkflowState:
    """Find email contacts using Hunter.io - Node: Hunter"""
    domain = state.get("company_domain")
    if not domain or not HUNTER_API_KEY:
        return state
    
    logger.info(f"Finding contacts for domain: {domain}")
    
    try:
        time.sleep(HUNTER_API_DELAY)  # Rate limiting
        
        url = "https://api.hunter.io/v2/domain-search"
        params = {
            'domain': domain,
            'api_key': HUNTER_API_KEY,
            'limit': 10
        }
        
        response = requests.get(url, params=params)
        response.raise_for_status()
        
        data = response.json()
        
        if data.get('data'):
            emails = data['data'].get('emails', [])
            organization = data['data'].get('organization', 'Unknown Company')
            
            logger.info(f"Found {len(emails)} email addresses")
            
            return {
                **state,
                "hunter_results": data['data'],
                "contact_emails": emails,
                "organization_name": organization,
                "emails_found": len(emails) > 0
            }
        else:
            return {**state, "emails_found": False}
            
    except Exception as e:
        logger.error(f"Error with Hunter.io API: {e}")
        return {
            **state,
            "emails_found": False,
            "errors": state.get("errors", []) + [f"Hunter.io error: {str(e)}"]
        }

def prepare_update_data(state: WorkflowState) -> WorkflowState:
    """Prepare data for success logging - Node: Edit Fields-Prepare Update Data"""
    logger.info("Preparing update data for success logging")
    return {**state, "success_logged": False}

def generate_email_body(state: WorkflowState) -> WorkflowState:
    """Generate personalized email body - Node: OpenAI1-email body"""
    if not state.get("emails_found") or not OPENAI_CLIENT:
        return state
    
    logger.info("Generating personalized email body")
    
    try:
        emails = state.get("contact_emails", [])
        if not emails:
            return state
            
        first_email = emails[0]
        first_name = first_email.get('first_name', 'there')
        last_name = first_email.get('last_name', '')
        
        prompt = f"""AVOID PURPLE PROSE. USE AS FEW WORDS AS POSSIBLE.

USE THESE FOLLOWING EXAMPLES AS THEY'RE VERY GOOD. STICK VERY CLOSE TO THIS STYLE AND EXACT TONE.

EXAMPLE 1:

Hey Tom,

I lead the team at AgentHub.dev and found you online when looking for Intelligent Automation consultants. We're an AI-first intelligent automation platform.

We're backed by the same people as AirBnB and Doordash but looking to explore collaborating with existing companies in the field.

Would love to chat this week if you're open to it.

EXAMPLE 2:

Hey Priti,

Hope this cold email is alright â€” found Cognizant's website and thought I'd reach out since we're building in the intelligent automation space.

I lead the team at AgentHub.dev, we're an AI-first intelligent automation tool. We're backed by the same people as AirBnB and Doordash but fully focused on helping businesses automate work with AI.

Would love to chat about potential collaboration if you're open to it.

ALWAYS SIGN OFF WITH:

-----
Best
Kaushalya N
Co-Founder

Context:
Summary of company: {state.get('company_summary', 'N/A')}
Contact person: {first_name} {last_name}"""

        response = OPENAI_CLIENT.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=300,
            temperature=0.7
        )
        
        email_body = response.choices[0].message.content
        logger.info("Email body generated successfully")
        
        return {**state, "email_body": email_body, "target_email": first_email.get('value')}
        
    except Exception as e:
        logger.error(f"Error generating email body: {e}")
        return {
            **state,
            "errors": state.get("errors", []) + [f"Email body generation error: {str(e)}"]
        }

def generate_email_subject(state: WorkflowState) -> WorkflowState:
    """Generate email subject line - Node: OpenAI-subject"""
    if not state.get("email_body") or not OPENAI_CLIENT:
        return state
    
    logger.info("Generating email subject line")
    
    try:
        emails = state.get("contact_emails", [])
        first_email = emails[0] if emails else {}
        first_name = first_email.get('first_name', 'there')
        last_name = first_email.get('last_name', '')
        
        prompt = f"""Context:
Summary of company: {state.get('company_summary', 'N/A')}
Company Name: {state.get('organization_name', 'Your Company')}
Contact person: {first_name} {last_name}

Write a 3 to 4 word subject to grab their attention. Mention their company name and partnership.
Here is an example: 'Potential Partnership with Cognizant'"""

        response = OPENAI_CLIENT.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=20,
            temperature=0.7
        )
        
        subject = response.choices[0].message.content.strip()
        logger.info(f"Subject generated: {subject}")
        
        return {**state, "email_subject": subject}
        
    except Exception as e:
        logger.error(f"Error generating subject: {e}")
        return {
            **state,
            "errors": state.get("errors", []) + [f"Subject generation error: {str(e)}"]
        }

def create_gmail_draft(state: WorkflowState) -> WorkflowState:
    """Create Gmail draft - Node: Gmail"""
    if not state.get("email_subject") or not state.get("email_body"):
        return state
    
    logger.info(f"Creating Gmail draft for {state.get('target_email')}")
    
    try:
        creds = get_google_credentials()
        service = build('gmail', 'v1', credentials=creds)
        
        # Create message
        message = {
            'to': state.get('target_email'),
            'subject': state.get('email_subject'),
            'body': state.get('email_body')
        }
        
        # Create draft
        draft = {
            'message': {
                'raw': create_message_raw(
                    message['to'],
                    message['subject'],
                    message['body']
                )
            }
        }
        
        result = service.users().drafts().create(userId='me', body=draft).execute()
        
        draft_id = result.get('id')
        logger.info(f"Draft created with ID: {draft_id}")
        
        return {**state, "draft_id": draft_id}
        
    except Exception as e:
        logger.error(f"Error creating Gmail draft: {e}")
        return {
            **state,
            "errors": state.get("errors", []) + [f"Gmail draft error: {str(e)}"]
        }

def create_message_raw(to, subject, body):
    """Create a raw message for Gmail API"""
    import base64
    from email.mime.text import MIMEText
    
    message = MIMEText(body)
    message['to'] = to
    message['subject'] = subject
    
    raw = base64.urlsafe_b64encode(message.as_bytes()).decode()
    return raw

def update_success_log(state: WorkflowState) -> WorkflowState:
    """Update Google Sheets with successful contact - Node: Google Sheets - Update Success Log"""
    if not state.get("draft_id") or state.get("success_logged"):
        return state
    
    logger.info("Updating success log in Google Sheets")
    
    try:
        creds = get_google_credentials()
        service = build('sheets', 'v4', credentials=creds)
        
        emails = state.get("contact_emails", [])
        if not emails:
            return state
            
        first_email = emails[0]
        
        # Prepare row data
        row_data = [[
            state.get("current_company_url"),
            first_email.get('value', ''),
            f"{first_email.get('first_name', '')} {first_email.get('last_name', '')}"
        ]]
        
        # Append to Sheet1
        body = {'values': row_data}
        result = service.spreadsheets().values().append(
            spreadsheetId=GOOGLE_SHEETS_SPREADSHEET_ID,
            range='Sheet1!A:C',
            valueInputOption='RAW',
            body=body
        ).execute()
        
        logger.info("Success log updated")
        return {**state, "success_logged": True}
        
    except Exception as e:
        logger.error(f"Error updating success log: {e}")
        return {
            **state,
            "errors": state.get("errors", []) + [f"Success log update error: {str(e)}"]
        }

def log_failed_lookup(state: WorkflowState) -> WorkflowState:
    """Log failed email lookups - Node: Google Sheets- Log Failed Lookups"""
    if state.get("emails_found") or state.get("failure_logged"):
        return state
    
    logger.info("Logging failed lookup to Google Sheets")
    
    try:
        creds = get_google_credentials()
        service = build('sheets', 'v4', credentials=creds)
        
        # Prepare row data
        row_data = [[state.get("company_domain", state.get("current_company_url", ""))]]
        
        # Append to Failures sheet
        body = {'values': row_data}
        result = service.spreadsheets().values().append(
            spreadsheetId=GOOGLE_SHEETS_SPREADSHEET_ID,
            range='Failures!A:A',
            valueInputOption='RAW',
            body=body
        ).execute()
        
        logger.info("Failed lookup logged")
        return {**state, "failure_logged": True}
        
    except Exception as e:
        logger.error(f"Error logging failed lookup: {e}")
        return {
            **state,
            "errors": state.get("errors", []) + [f"Failed lookup log error: {str(e)}"]
        }

def increment_index(state: WorkflowState) -> WorkflowState:
    """Move to the next company in the list"""
    current_index = state.get("current_index", 0)
    logger.info(f"Moving to next company (index {current_index + 1})")
    return {**state, "current_index": current_index + 1}

# ============================================================================
# CONDITIONAL EDGES
# ============================================================================

def should_continue_processing(state: WorkflowState) -> str:
    """Determine if we should continue processing companies"""
    if state.get("processing_complete", False):
        return "end"
    
    current_index = state.get("current_index", 0)
    company_urls = state.get("company_urls", [])
    
    if current_index >= len(company_urls):
        return "end"
    else:
        return "continue"

def check_emails_found(state: WorkflowState) -> str:
    """Check if emails were found - implements If node logic"""
    if state.get("emails_found", False):
        return "success"
    else:
        return "failure"

# ============================================================================
# GRAPH CONSTRUCTION
# ============================================================================

def create_workflow_graph() -> StateGraph:
    """Create and configure the LangGraph workflow"""
    
    # Initialize the graph with our state schema
    workflow = StateGraph(WorkflowState)
    
    # Add all nodes
    workflow.add_node("initialize", initialize_workflow)
    workflow.add_node("read_sheets", read_google_sheets)
    workflow.add_node("select_company", select_next_company)
    workflow.add_node("fetch_website", fetch_website)
    workflow.add_node("extract_text", extract_text_content)
    workflow.add_node("summarize", summarize_company)
    workflow.add_node("find_contacts", find_contacts)
    workflow.add_node("prepare_update", prepare_update_data)
    workflow.add_node("generate_body", generate_email_body)
    workflow.add_node("generate_subject", generate_email_subject)
    workflow.add_node("create_draft", create_gmail_draft)
    workflow.add_node("update_success", update_success_log)
    workflow.add_node("log_failure", log_failed_lookup)
    workflow.add_node("increment", increment_index)
    
    # Set the entry point
    workflow.set_entry_point("initialize")
    
    # Add edges for the main flow
    workflow.add_edge("initialize", "read_sheets")
    workflow.add_edge("read_sheets", "select_company")
    
    # Conditional edge: check if we should continue processing
    workflow.add_conditional_edges(
        "select_company",
        should_continue_processing,
        {
            "continue": "fetch_website",
            "end": END
        }
    )
    
    # Main processing pipeline for each company
    workflow.add_edge("fetch_website", "extract_text")
    workflow.add_edge("extract_text", "summarize")
    workflow.add_edge("summarize", "find_contacts")
    
    # Conditional edge: check if emails were found (If node)
    workflow.add_conditional_edges(
        "find_contacts",
        check_emails_found,
        {
            "success": "prepare_update",
            "failure": "log_failure"
        }
    )
    
    # Success path: generate email and update logs
    workflow.add_edge("prepare_update", "generate_body")
    workflow.add_edge("generate_body", "generate_subject")
    workflow.add_edge("generate_subject", "create_draft")
    workflow.add_edge("create_draft", "update_success")
    workflow.add_edge("update_success", "increment")
    
    # Failure path: log and continue
    workflow.add_edge("log_failure", "increment")
    
    # Loop back to select next company
    workflow.add_edge("increment", "select_company")
    
    return workflow.compile()

# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main execution function"""
    logger.info("=== Starting Automated Outbound Sales Workflow ===")
    
    # Validate configuration
    if not OPENAI_API_KEY:
        logger.error("OPENAI_API_KEY not set")
        return
    
    if not HUNTER_API_KEY:
        logger.error("HUNTER_API_KEY not set")
        return
    
    # Create the workflow
    app = create_workflow_graph()
    
    # Initialize state
    initial_state = WorkflowState(
        company_urls=[],
        current_index=0,
        current_company_url=None,
        html_content=None,
        text_content=None,
        company_summary=None,
        company_domain=None,
        hunter_results=None,
        contact_emails=[],
        organization_name=None,
        email_body=None,
        email_subject=None,
        target_email=None,
        emails_found=False,
        processing_complete=False,
        success_logged=False,
        failure_logged=False,
        errors=[],
        draft_id=None
    )
    
    # Run the workflow
    try:
        result = app.invoke(initial_state,{"recursion_limit": 100})
        
        # Log summary
        logger.info("=== Workflow Completed ===")
        logger.info(f"Total companies processed: {result.get('current_index', 0)}")
        
        if result.get('errors'):
            logger.warning(f"Errors encountered: {result['errors']}")
        
    except Exception as e:
        logger.error(f"Workflow execution failed: {e}")
        raise

if __name__ == "__main__":
    main()